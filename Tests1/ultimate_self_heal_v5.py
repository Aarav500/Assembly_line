#!/usr/bin/env python3
"""
ultimate_self_heal_v5.py

Enhanced Ultimate Self-Healing test runner.
Reads a CSV (summary.csv by default) containing modules/projects and their
test status/errors, runs pytest for failed entries, attempts automated fixes,
and loops in waves until everything passes or limits are reached.

Features:
- smart pytest invocation (uses pytest if on PATH, else python -m pytest)
- auto-installs pytest if missing
- fixes: missing __init__.py, pytest.ini BOM, encoding, simple syntax fixes,
  dependency version reconciliation for common conflicts (flask, werkzeug, rich, marshmallow)
- adds smoke tests where absent
- retries until all pass or max limits
- writes summary_updated.csv with results and logs
"""

import csv
import subprocess
import time
import argparse
from pathlib import Path
import shutil
import sys
import re
import json

# ----------------------
# Configurable defaults
# ----------------------
DEFAULT_CSV = "summary.csv"
UPDATED_CSV = "summary_updated.csv"
PYTEST_TIMEOUT = 600            # seconds per pytest run
WAVE_PAUSE = 3                  # seconds between waves
PER_MODULE_PAUSE = 1            # seconds between module attempts
MAX_WAVES = 30
MAX_ITERS_PER_MODULE = 25
SMOKE_TEST_CONTENT = """import pytest
from pathlib import Path
def test_module_exists():
    p = Path(__file__).parent
    py_files = list(p.glob("*.py"))
    assert len(py_files) > 0
def test_syntax_ok():
    import ast
    p = Path(__file__).parent
    for f in p.glob("*.py"):
        if f.name.startswith("test_"):
            continue
        src = f.read_text(encoding='utf-8', errors='ignore')
        try:
            ast.parse(src)
        except SyntaxError as e:
            pytest.fail(f"Syntax error in {f}: {e}")
"""

# ----------------------
# Utilities
# ----------------------
def debug(msg):
    print(msg)

def detect_pytest_cmd():
    """Return a command list to invoke pytest robustly on Windows and POSIX."""
    # prefer pytest on PATH
    if shutil.which("pytest"):
        return ["pytest"]
    # fallback to using python -m pytest
    return [sys.executable, "-m", "pytest"]

def ensure_pytest_installed():
    """Ensure pytest is installed in the current environment; installs if needed."""
    cmd = detect_pytest_cmd()
    if cmd[0] == "pytest":
        debug("pytest detected on PATH.")
        return True
    # try invoking python -m pytest --version to confirm
    try:
        res = subprocess.run([sys.executable, "-m", "pytest", "--version"],
                             capture_output=True, text=True, timeout=20)
        if res.returncode == 0:
            debug("pytest available via python -m pytest.")
            return True
    except Exception:
        pass
    # install pytest & pytest-html
    debug("pytest missing â€” installing pytest and pytest-html into current environment...")
    res = subprocess.run([sys.executable, "-m", "pip", "install", "--no-cache-dir", "pytest", "pytest-html"],
                         capture_output=True, text=True)
    if res.returncode == 0:
        debug("Installed pytest successfully.")
        return True
    debug("Failed to install pytest automatically. See pip output:")
    debug(res.stdout)
    debug(res.stderr)
    return False

def run_subprocess(cmd_list, timeout=None):
    """Wrapper to run subprocess and return (returncode, stdout+stderr)."""
    try:
        res = subprocess.run(cmd_list, capture_output=True, text=True, timeout=timeout)
        return res.returncode, (res.stdout or "") + (res.stderr or "")
    except subprocess.TimeoutExpired as e:
        return 124, f"TIMEOUT after {timeout}s\n{str(e)}"
    except FileNotFoundError as e:
        return 127, f"FILE NOT FOUND: {e}"
    except Exception as e:
        return 1, f"ERROR running subprocess: {e}"

def run_pytest_for_path(target_path):
    """Run pytest for a folder or file, using robust invocation and timeout."""
    cmd = detect_pytest_cmd()
    # run pytest -q <target_path>
    full_cmd = cmd + ["-q", str(target_path)]
    code, out = run_subprocess(full_cmd, timeout=PYTEST_TIMEOUT)
    # If file not found or exit 127, try python -m pytest explicitly
    if code in (127, 1) and cmd[0] != sys.executable:
        full_cmd = [sys.executable, "-m", "pytest", "-q", str(target_path)]
        code, out = run_subprocess(full_cmd, timeout=PYTEST_TIMEOUT)
    return code, out

def normalize_fieldnames(fieldnames):
    mapping = {}
    for n in (fieldnames or []):
        if not n:
            continue
        ln = n.lower().strip()
        if "path" in ln or "full" in ln:
            mapping["FullPath"] = n
        elif "file" in ln and "name" in ln:
            mapping["FileName"] = n
        elif "status" in ln:
            mapping["Status"] = n
        elif "error" in ln or "trace" in ln or "output" in ln:
            mapping["Error"] = n
    return mapping

# ----------------------
# Auto-fix helpers
# ----------------------
def safe_write_text(path: Path, text: str, encoding="utf-8"):
    path.write_text(text, encoding=encoding)

def fix_pytest_ini_bom(project_root: Path):
    ini = project_root / "pytest.ini"
    if ini.exists():
        content = ini.read_bytes()
        if content.startswith(b'\xef\xbb\xbf'):
            # remove BOM
            new = content.lstrip(b'\xef\xbb\xbf')
            ini.write_bytes(new)
            debug(f"Fixed BOM in {ini}")
            return True
    return False

def reencode_py_files_to_utf8(project_root: Path):
    changed = 0
    for p in project_root.rglob("*.py"):
        try:
            raw = p.read_bytes()
            # try decode as utf-8, if fails decode with errors and rewrite
            try:
                raw.decode("utf-8")
            except Exception:
                text = raw.decode("utf-8", errors="ignore")
                p.write_text(text, encoding="utf-8")
                changed += 1
        except Exception:
            continue
    if changed:
        debug(f"Re-encoded {changed} .py files to utf-8 in {project_root}")
    return changed

def add_missing_init(project_root: Path):
    created = 0
    for d in project_root.rglob("*"):
        if d.is_dir():
            init = d / "__init__.py"
            if not init.exists():
                try:
                    init.write_text("# auto-created\n", encoding="utf-8")
                    created += 1
                except Exception:
                    pass
    if created:
        debug(f"Created {created} missing __init__.py files under {project_root}")
    return created

def add_smoke_test_if_missing(project_root: Path):
    added = 0
    for d in [project_root]:
        if not d.exists():
            continue
        test_file = d / "test_smoke.py"
        # only add if no tests exist
        tests = list(d.glob("test_*.py"))
        if not tests:
            try:
                test_file.write_text(SMOKE_TEST_CONTENT, encoding="utf-8")
                added += 1
                debug(f"Added smoke test {test_file}")
            except Exception:
                pass
    return added

def create_placeholder_app(project_root: Path):
    # safe placeholder flask app if missing
    app_py = project_root / "app.py"
    if not app_py.exists():
        try:
            app_py.write_text("from flask import Flask\napp = Flask(__name__)\n@app.route('/')\ndef index():\n    return 'ok'\n", encoding="utf-8")
            debug(f"Created placeholder app.py in {project_root}")
            return True
        except Exception:
            pass
    return False

def attempt_dependency_fixes(output_text):
    """
    Parse output_text for known dependency conflicts and apply force-reinstalls
    for conservative, known-good versions.
    """
    fixes_applied = []
    # patterns and target pinned versions - conservative choices
    desired = {
        "flask-smorest.*requires.*flask": ("flask", "3.0.3"),
        "flask-limiter.*requires.*rich": ("rich", "13.7.1"),
        "requires marshmallow==3.23.1": ("marshmallow", "3.23.1"),
        "flask-smorest.*requires.*werkzeug": ("werkzeug", "3.0.3"),
    }
    for pat, (pkg, ver) in desired.items():
        try:
            if re.search(pat, output_text, flags=re.IGNORECASE):
                cmd = [sys.executable, "-m", "pip", "install", "--no-cache-dir", f"{pkg}=={ver}", "--force-reinstall"]
                debug(f"Attempting dependency fix: {' '.join(cmd)}")
                rc, out = run_subprocess(cmd, timeout=300)
                if rc == 0:
                    fixes_applied.append(f"{pkg}=={ver}")
                else:
                    debug(f"Failed to apply dependency fix for {pkg}: {out[:800]}")
        except re.error:
            continue
    # generic fixes: if message mentions "rich 14.2.0" or similar, try earlier rich
    if "rich 14" in output_text and "flask-limiter" in output_text:
        cmd = [sys.executable, "-m", "pip", "install", "--no-cache-dir", "rich==13.7.1", "--force-reinstall"]
        rc, out = run_subprocess(cmd, timeout=300)
        if rc == 0:
            fixes_applied.append("rich==13.7.1")
    return fixes_applied

def generic_fallback_fix(project_root: Path, output_text: str):
    """
    Apply a collection of conservative repairs for many common issues.
    Returns list of applied fixes as strings.
    """
    applied = []
    # BOM fix
    if fix_pytest_ini_bom(project_root):
        applied.append("fixed-pytest-ini-bom")
    # re-encode py files to utf-8
    changed = reencode_py_files_to_utf8(project_root)
    if changed:
        applied.append(f"reencoded-{changed}-py")
    # add missing __init__.py
    created = add_missing_init(project_root)
    if created:
        applied.append(f"created-{created}-init")
    # add smoke tests if none
    smoke_added = add_smoke_test_if_missing(project_root)
    if smoke_added:
        applied.append("added-smoke-test")
    # placeholder app.py if referenced in errors
    if ("flask" in output_text.lower() or "wsgi" in output_text.lower()):
        if create_placeholder_app(project_root):
            applied.append("created-app-py")
    # try dependency fixes
    dep_fixed = attempt_dependency_fixes(output_text)
    applied.extend(dep_fixed)
    # attempt an editable install if pyproject/setup present
    if (project_root / "setup.py").exists() or (project_root / "pyproject.toml").exists():
        cmd = [sys.executable, "-m", "pip", "install", "--no-cache-dir", "-e", str(project_root)]
        rc, out = run_subprocess(cmd, timeout=600)
        if rc == 0:
            applied.append("editable-install")
        else:
            debug(f"Editable install failed for {project_root}: {out[:800]}")
    return applied

# ----------------------
# Core processing
# ----------------------
def process_module_row(row, field_map, args):
    name = row.get(field_map.get("FileName", ""), "") or row.get(field_map.get("FullPath", ""), "")
    raw_path = row.get(field_map.get("FullPath", ""), "")
    error_text = row.get(field_map.get("Error", ""), "") or ""
    status = (row.get(field_map.get("Status", ""), "") or "").strip().upper()

    # determine a sensible project folder
    p = Path(raw_path) if raw_path else Path(name)
    if p.is_file():
        project_root = p.parent
    else:
        project_root = p

    # if still not existing, try to find by scanning common folders
    if not project_root.exists():
        # maybe the CSV contains a report file that sits inside the project folder (like reports/report_a-001.html)
        # attempt to find the project by filename prefix in current tree
        possible = list(Path(".").rglob("*" + Path(raw_path).stem + "*"))
        if possible:
            project_root = possible[0].parent
            debug(f"Resolved project path for {name} -> {project_root}")
        else:
            debug(f"Project path not found for {name} ({raw_path}); skipping.")
            return {"name": name, "path": str(project_root), "status": "MISSING_PATH", "attempts": 0, "last_output": ""}

    # main healing loop per module
    iteration = 0
    last_output = ""
    healed = False
    fixes_applied_total = []
    while iteration < MAX_ITERS_PER_MODULE:
        iteration += 1
        time.sleep(PER_MODULE_PAUSE)
        debug(f"\nâ–¶ Iteration {iteration} for module {name} at {project_root}")
        # Run pytest for this project_root
        rc, out = run_pytest_for_path(project_root)
        last_output = out[:50000]  # keep snippet
        if rc == 0:
            healed = True
            debug(f"âœ… Module {name} PASSED after {iteration} iter(s).")
            break
        else:
            debug(f"âŒ Module {name} failed (rc={rc}). Parsing output for fixes...")
            # Try conservative fixes
            fixes = generic_fallback_fix(project_root, out)
            fixes_applied_total.extend(fixes)
            if not fixes:
                debug("âš  No auto-fix matched. Attempting some heuristics...")
                # heuristic: ensure pytest.ini BOM removed in root
                fix_pytest_ini_bom(project_root)
                # add __init__.py and smoke test again
                add_missing_init(project_root)
                add_smoke_test_if_missing(project_root)
            # step pause before re-run
            time.sleep(1)
    # end per-module attempts
    result_status = "PASSED" if healed else "FAILED"
    return {
        "name": name,
        "path": str(project_root),
        "status": result_status,
        "attempts": iteration,
        "last_output": last_output,
        "fixes": fixes_applied_total
    }

def load_csv(csv_path):
    with open(csv_path, newline='', encoding="utf-8", errors="ignore") as f:
        reader = csv.DictReader(f)
        rows = [r for r in reader]
        field_map = normalize_fieldnames(reader.fieldnames or [])
        return rows, field_map

def write_updated_csv(original_rows, field_map, results, out_path=UPDATED_CSV):
    # Merge results into rows by matching path or filename
    # We'll produce an updated CSV with appended columns: HealedStatus, Attempts, LastOutput, Fixes
    updated_rows = []
    res_map = {}
    for r in results:
        key = (r.get("path") or "").lower()
        res_map[key] = r

    # Build headers
    headers = []
    if original_rows:
        headers = list(original_rows[0].keys())
    for extra in ("HealedStatus", "Attempts", "LastOutput", "Fixes"):
        if extra not in headers:
            headers.append(extra)

    for row in original_rows:
        fullpath = (row.get(field_map.get("FullPath", ""), "") or "").strip()
        key = fullpath.lower()
        new_row = dict(row)
        if key in res_map:
            r = res_map[key]
            new_row["HealedStatus"] = r["status"]
            new_row["Attempts"] = r["attempts"]
            # compress last_output to small JSON-friendly excerpt (escape newlines)
            lo = r.get("last_output", "").replace("\n", "\\n").replace("\r", "")
            new_row["LastOutput"] = lo[:10000]
            new_row["Fixes"] = ",".join(r.get("fixes", []))
        else:
            # unchanged
            new_row["HealedStatus"] = row.get(field_map.get("Status", ""), "")
            new_row["Attempts"] = ""
            new_row["LastOutput"] = ""
            new_row["Fixes"] = ""
        updated_rows.append(new_row)

    # write CSV
    with open(out_path, "w", newline='', encoding="utf-8") as f:
        writer = csv.DictWriter(f, fieldnames=headers)
        writer.writeheader()
        writer.writerows(updated_rows)
    debug(f"Wrote updated CSV to {out_path}")

# ----------------------
# Main orchestration
# ----------------------
def main():
    global MAX_WAVES, MAX_ITERS_PER_MODULE
    parser = argparse.ArgumentParser(description="Ultimate Self-Heal v5")
    parser.add_argument("--csv", default=DEFAULT_CSV, help="Path to summary CSV")
    parser.add_argument("--max-waves", type=int, default=MAX_WAVES, help="Max healing waves")
    parser.add_argument("--max-iters", type=int, default=MAX_ITERS_PER_MODULE, help="Max iterations per module")
    parser.add_argument("--force-all", action="store_true", help="Force processing of all rows even PASSED")
    args = parser.parse_args()


    MAX_WAVES = args.max_waves
    MAX_ITERS_PER_MODULE = args.max_iters

    csv_path = Path(args.csv)
    if not csv_path.exists():
        print(f"CSV not found: {csv_path}")
        return

    rows, field_map = load_csv(csv_path)
    if not field_map:
        print("Could not detect necessary CSV headers. Expected columns like: FileName, FullPath, Status, Error")
        print("Detected columns:", (rows[0].keys() if rows else []))
        return

    # Ensure pytest present or install
    if not ensure_pytest_installed():
        print("pytest not available and automatic install failed. Exiting.")
        return

    total = len(rows)
    debug(f"Loaded {total} entries from {csv_path}. Field mapping: {field_map}")

    # We'll process in waves; after each wave we write an updated CSV and compute pass rate
    results_by_path = {}
    for wave in range(1, MAX_WAVES + 1):
        debug("\n" + "="*80)
        debug(f"ðŸ” Healing Wave {wave}/{MAX_WAVES}")
        debug("="*80)
        to_process = []
        # choose rows to process: either failed or forced
        for r in rows:
            status = (r.get(field_map.get("Status", ""), "") or "").strip().upper()
            fullpath = (r.get(field_map.get("FullPath", ""), "") or "").strip()
            if args.force_all or status in ("FAILED", "ERROR", "NO TESTS", ""):
                # avoid duplicate processing if already healed
                if fullpath.lower() in results_by_path and results_by_path[fullpath.lower()]["status"] == "PASSED":
                    continue
                to_process.append(r)

        if not to_process:
            debug("No modules to process this wave. Checking overall pass rate...")
            # compute pass rate
            passed = 0
            for r in rows:
                status = (r.get(field_map.get("Status", ""), "") or "").strip().upper()
                if status == "PASSED" or results_by_path.get((r.get(field_map.get("FullPath", ""), "") or "").lower(), {}).get("status") == "PASSED":
                    passed += 1
            pass_rate = (passed / total) * 100 if total else 100.0
            debug(f"Current pass rate: {pass_rate:.2f}% ({passed}/{total})")
            if pass_rate >= 100.0:
                debug("All modules passed. Exiting.")
                break
            else:
                debug("No candidates to process but not 100% yet. Breaking to avoid infinite loop.")
                break

        wave_results = []
        for r in to_process:
            res = process_module_row(r, field_map, args)
            wave_results.append(res)
            results_by_path[res["path"].lower()] = res

        # after wave, write updated CSV
        write_updated_csv(rows, field_map, list(results_by_path.values()), out_path=UPDATED_CSV)

        # compute pass rate
        passed = sum(1 for v in results_by_path.values() if v["status"] == "PASSED")
        # merge with original passed count
        orig_pass = sum(1 for r in rows if (r.get(field_map.get("Status", ""), "") or "").strip().upper() == "PASSED")
        total_pass = passed + orig_pass
        pass_rate = (total_pass / total) * 100 if total else 100.0
        debug(f"Wave {wave} complete. Total pass rate: {pass_rate:.2f}% ({total_pass}/{total})")
        debug(f"Wave fixes summary (sample):")
        # show small sample
        sample = wave_results[:10]
        for s in sample:
            debug(f" - {s['name']} -> {s['status']} (attempts={s['attempts']}) fixes={s.get('fixes',[])[:5]}")
        # stop if all passed
        if pass_rate >= 100.0:
            debug("Reached 100% pass rate.")
            break
        debug(f"Sleeping {WAVE_PAUSE}s before next wave...")
        time.sleep(WAVE_PAUSE)

    debug("Healing run complete. Final summary written to " + UPDATED_CSV)
    # print final summary counts
    healed_count = sum(1 for v in results_by_path.values() if v["status"] == "PASSED")
    failed_count = sum(1 for v in results_by_path.values() if v["status"] != "PASSED")
    debug(f"Healed: {healed_count}, Still failing: {failed_count}, Total modules processed: {len(results_by_path)}")

if __name__ == "__main__":
    main()
